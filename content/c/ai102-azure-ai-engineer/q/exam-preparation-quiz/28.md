---
title: "Understand Azure OpenAI Response Truncation Behavior"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: "Yes"
      correct: false
      explain: "The completion tokens (86) are well below the max response tokens limit (100), and the finish_reason is 'stop', indicating natural completion rather than truncation."
    - id: "answer2"
      title: "No"
      correct: true
      explain: "The response was not truncated - the finish_reason shows 'stop' which means the model completed its response naturally, and 86 tokens is below the 100-token limit."
    - id: "answer3"
      title: "Only if including prompt tokens"
      correct: false
      explain: "Max response tokens only applies to the generated response (completion tokens), not the input prompt tokens, so prompt tokens don't affect truncation."
    - id: "answer4"
      title: "Cannot determine from the response"
      correct: false
      explain: "The finish_reason field clearly indicates whether truncation occurred - 'stop' means natural completion while 'length' would indicate truncation."
link: "https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/completions"
more: "Learn more about Azure OpenAI response handling"
learn: "Azure OpenAI Responses"
---

MDFT Pro, a well-known training agency, is testing their Azure OpenAI-powered course recommendation system to ensure it provides complete and helpful responses to student inquiries. Claire, the Quality Assurance Specialist, is analyzing system behavior to understand when responses might be cut off due to token limits, which could result in incomplete recommendations or answers to student questions. 

The team needs to properly configure response limits to balance comprehensive answers with cost control, ensuring students receive complete information about course offerings, prerequisites, and enrollment procedures without unnecessary token consumption.

The system is configured with the following settings:
- Temperature: 1
- Top probabilities: 0.5  
- Max response tokens: 100

When asked about MDFT Pro's founder, the system returns this response:

```json
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "content": "The founder of MDFT Pro is Mark Farragher.",
        "role": "assistant"
      }
    }
  ],
  "created": 1679014554,
  "id": "chatcmpl-6usfny2yyjkbmESe36JdqQ6bDsc01",
  "model": "gpt-3.5-turbo-0301",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 86,
    "prompt_tokens": 37,
    "total_tokens": 123
  }
}
```

Was the text completion truncated because the Max response tokens value was exceeded?
