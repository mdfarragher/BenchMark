---
title: "Implement Azure AI Content Safety For Educational Chatbot Security"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: "Protected material text detection"
      correct: false
      explain: "Protected material detection identifies copyrighted content but doesn't specifically address attempts to bypass safety mechanisms in AI conversations."
    - id: "answer2"
      title: "Jailbreak risk detection"
      correct: true
      explain: "Jailbreak risk detection specifically identifies and blocks prompts that attempt to circumvent built-in safety features and content policies."
    - id: "answer3"
      title: "Monitor online activity"
      correct: false
      explain: "Monitoring online activity is a general security measure but doesn't address specific attempts to bypass AI safety features through prompt manipulation."
    - id: "answer4"
      title: "Moderate text content"
      correct: false
      explain: "Text content moderation filters inappropriate content but may not catch sophisticated attempts to circumvent safety guardrails through crafted prompts."
link: "https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/jailbreak-detection"
more: "Learn more about jailbreak risk detection"
learn: "Jailbreak Risk Detection"
---

MDFT Pro, a well-known training agency, has developed an AI-powered student support chatbot using Azure OpenAI to help students with course-related questions, study guidance, and career advice. Mark, the AI Safety Coordinator, has noticed that some students are attempting to manipulate the chatbot through carefully crafted prompts designed to bypass the built-in safety features and generate inappropriate or harmful content. 

These "jailbreak" attempts could potentially expose students to unsuitable responses or compromise the educational integrity of the platform. Mark needs to implement additional safety measures to ensure the chatbot maintains appropriate boundaries and continues to provide safe, educational interactions for all students.

Which Azure AI Content Safety feature should Mark implement to block questions intended to circumvent built-in safety features?
