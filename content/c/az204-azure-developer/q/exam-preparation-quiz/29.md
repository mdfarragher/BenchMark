---
title: "Configure Azure Batch Output File Upload Condition"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: "TaskSuccess"
      correct: true
      explain: "TaskSuccess specifies that output files should only be uploaded when the task completes successfully. Since the requirement is to store successfully converted files in the output container, this condition ensures that only files from successful conversions are uploaded, preventing corrupted or partially processed files from being stored."
    - id: "answer2"
      title: "TaskFailure"
      correct: false
      explain: "TaskFailure would upload output files only when tasks fail. This is the opposite of what's neededâ€”you want to store successfully converted files, not output from failed conversions. Using TaskFailure would mean successful conversions aren't saved."
    - id: "answer3"
      title: "TaskCompletion"
      correct: false
      explain: "TaskCompletion uploads files regardless of whether the task succeeded or failed. This would store output from both successful and failed conversion attempts, potentially including corrupted or incomplete files in the output container. The requirement specifically states only successfully converted files should be stored."
    - id: "answer4"
      title: "TaskStarted"
      correct: false
      explain: "TaskStarted is not a valid OutputFileUploadCondition value in the Azure Batch SDK. Output files are uploaded after task execution, not when tasks start, since the output files are created during task execution. The valid conditions are TaskSuccess, TaskFailure, and TaskCompletion."
link: "https://learn.microsoft.com/en-us/azure/batch/batch-task-output-files"
more: "Learn more about Batch Task Output Files"
learn: "Persist Task Output"
---

You work as a Batch Processing Developer for MDFT Pro, a well-known training agency that provides certification courses to students globally. Mark, the Systems Integration Lead, has tasked you with developing an Azure Batch solution that processes and converts student assignment submissions stored in Azure Storage. 

The system needs to batch convert video presentations, PDF documents, and code projects submitted by students into standardized formats for grading and archival. You've created a function called **StartTasks** that accepts three parameters: 

| Parameter name |Description |
| -------------- |------------|
| fileTasks      | a list of tasks to be run |
| jobId          | the identifier that must be assigned to the job |
| outputContainerSasUrl | a storage SAS URL to store successful converted files |

When one document has corrupted data and fails conversion, you still need to ensure all other successfully converted files are uploaded to the output container. Only successfully converted files should be placed in the container referenced by the **outputContainerSasUrl** parameter. Failed conversions should not be stored to avoid filling the container with invalid data.

How should you complete the code to configure the output file upload condition?

```csharp
public List<CloudTasks> StartTasks(List<FileTask> fileTasks, string jobId, string outputContainerSasUrl)
{
	// job setup code goes here
	// ...

	fileTasks.ForEach((fileTask) =>
	{
		var taskId = DateTime.Now.ToFileTimeUtc().ToString();
		var task = new CloudTask(taskId, fileTask.Command);
		var files = new List<OutputFile>();
		var outputContainer = new OutputFileBlobContainerDestination(outputContainerSasUrl);
		files.Add(
			new OutputFile(
				fileTask.Output,
				new OutputFileDestination(outputContainer),
				new OutputFileUploadOptions(OutputFileUploadCondition._________)
			)
		);
	}
}
```
