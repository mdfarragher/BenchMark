---
title: "Choose the Efficient Data Ingestion Method"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: "Download the data to your computer, then use Lakehouse explorer to upload it to TRAINHOUSE"
      explain: "Manual data transfer through downloading and uploading is inefficient, time-consuming, and prone to human error. It also requires unnecessary local storage and network bandwidth."
    - id: "answer2"
      title: "Use Dataflow Gen2"
      explain: "Dataflow Gen2 is designed for data transformation and preparation, not for simple data ingestion. It would add unnecessary complexity and processing overhead for this scenario."
    - id: "answer3"
      title: "Use a Spark notebook"
      explain: "While Spark notebooks can handle data ingestion, they require more development effort and computational resources than necessary for this simple ingestion task."
    - id: "answer4"
      title: "Use the Copy activity in a pipeline"
      correct: true

link: "https://learn.microsoft.com/en-us/fabric/data-factory/copy-data-activity"
more: "Learn more about the Copy Data activity in Fabric"
learn: "Copy Data Activity"
---
You work for MDFT Pro, a training agency that uses Microsoft Fabric for data analytics. Your team has forecast data stored in Azure Data Lake Storage Gen2 that needs to be ingested into a Fabric lakehouse named TRAINHOUSE. The data is already properly formatted and requires no additional transformations. 

Which method should you recommend to efficiently ingest the data while minimizing development effort and costs?
