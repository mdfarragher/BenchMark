---
title: "Add New Data to Delta Table with Additional Columns"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: |
        "mergeSchema", "true"
      correct: true
    - id: "answer2"
      title: |
        "mergeSchema", "false"
      explain: "Setting mergeSchema to false would prevent the new columns from being added to the table schema, which would cause the operation to fail since the new data contains additional columns."
    - id: "answer3"
      title: |
        "overwriteSchema", "true"
      explain: "Using overwriteSchema would replace the entire table schema, which could potentially cause data loss and is not the appropriate option for adding new data while preserving existing data."
    - id: "answer4"
      title: |
        "overwriteSchema", "false"
      explain: "Setting overwriteSchema to false would not allow the new columns to be added to the table schema, and would cause the operation to fail since the new data contains additional columns."

link: "https://learn.microsoft.com/en-us/azure/databricks/delta/update-schema#insert-evo"
more: "Learn more about schema evolution in Delta tables"
learn: "Schema Evolution"
---

MDFT Pro has a Fabric tenant containing a lakehouse named Lakehousel. The lakehouse contains a Delta table named `students` with eight columns. You receive new data that contains the same eight columns plus two additional columns.

You create a Spark DataFrame and assign it to a variable named `df`. The DataFrame contains the new data. You need to add the new data to the Delta table while meeting these requirements:

- Keep all existing rows in the table
- Ensure all new data is added to the table, including the extra columns

You have the following Python code:

```python
df.write.format("delta").mode("append").option( _____ ).saveAsTable("students")
```

How should you complete the code?

