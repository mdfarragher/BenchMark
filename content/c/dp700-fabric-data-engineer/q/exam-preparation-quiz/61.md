---
title: "Implement Filtered Batch Ingestion From Event Hubs"
type: "question"
layout: "multiple"
answers:
    - id: "answer1"
      title: "For data processing, use a data pipeline"
      correct: false
      explain: "Data pipelines are useful for orchestration and complex workflows, but they require more development effort compared to Dataflow Gen2 for simple filtering and transformation tasks."
    - id: "answer2"
      title: "For data processing, use a Dataflow Gen2 dataflow"
      correct: true
      explain: "Dataflow Gen2 provides a low-code interface for data transformation and filtering, making it ideal for batch processing scenarios with minimal development effort."
    - id: "answer3"
      title: "For data processing, use an eventstream with a custom endpoint"
      correct: false
      explain: "Custom endpoints in eventstreams are designed for routing data to external systems, not for batch processing and filtering operations."
    - id: "answer4"
      title: "For data processing, use an eventstream with an external data source"
      correct: false
      explain: "External data sources in eventstreams are used to connect to different data sources, not for processing and filtering data that's already being ingested."
    - id: "answer5"
      title: "For filtering, use a filter activity in a data pipeline"
      correct: false
      explain: "While data pipelines support filtering, they require more development effort and are better suited for complex orchestration rather than simple filter operations."
    - id: "answer6"
      title: "For filtering, use a filter in a Dataflow Gen2 dataflow"
      correct: true
      explain: "Dataflow Gen2 includes built-in filter transformations that can be easily configured with a low-code interface, minimizing development effort while effectively filtering rows based on attribute values."
    - id: "answer7"
      title: "For filtering, use a KQL query"
      correct: false
      explain: "KQL queries are used for querying data in KQL databases or Real-Time Analytics, not for filtering data in an eventstream ingestion pipeline before it reaches the lakehouse."
    - id: "answer8"
      title: "For filtering, use an eventstream processor"
      correct: false
      explain: "Eventstream processors are designed for real-time stream processing, not for batch ingestion scenarios where Dataflow Gen2 would be more appropriate."
link: "https://learn.microsoft.com/en-us/fabric/data-factory/dataflows-gen2-overview"
more: "Learn more about Dataflow Gen2 in Microsoft Fabric"
learn: "Dataflow Gen2 Overview"
---
You work as a Data Integration Specialist for Mark at MDFT Pro, a well-known training agency. MDFT Pro has deployed an Azure Event Hubs data source that continuously receives weather data from various training facility locations. You have set up an eventstream named Eventstream1 to ingest this data, with a lakehouse configured as the destination to store the weather information for analysis. Mark has requested that you implement batch ingestion to process only the rows where the City attribute has a value of "Kansas", as this is where MDFT Pro's main training campus is located. The filtering must be applied before the data reaches the lakehouse destination, and the solution must minimize development effort to keep implementation simple and maintainable.

What should you use for the data processor and filtering?
