---
title: "Resolve Data Refresh Issue Efficiently"
type: "question"
layout: "single"
answers:
    - id: "answer1"
      title: "Split the dataflow into two dataflows"
      correct: false
      explain: "Splitting the dataflow into multiple dataflows would add complexity and maintenance overhead without addressing the underlying issue of transferring excessive amounts of data during refresh operations."
    - id: "answer2"
      title: "Configure scheduled refresh for the dataflow"
      correct: false
      explain: "Scheduled refresh alone would still transfer all data during each refresh cycle, which doesn't minimize the amount of data transferred as required."
    - id: "answer3"
      title: "Configure incremental refresh for the dataflow. Set Store rows from the past to 1 Month"
      correct: false
      explain: "The 'Store rows from the past' setting determines how much historical data to retain, not how much data to refresh. This setting alone won't minimize data transfer during refresh operations."
    - id: "answer4"
      title: "Configure incremental refresh for the dataflow. Set Refresh rows from the past to 1 Year"
      correct: false
      explain: "Setting 'Refresh rows from the past' to 1 Year would refresh an entire year of data during each refresh cycle, which transfers significantly more data than necessary and doesn't minimize data transfer."
    - id: "answer5"
      title: "Configure incremental refresh for the dataflow. Set Refresh rows from the past to 1 Month"
      correct: true
      explain: "Incremental refresh with 'Refresh rows from the past' set to 1 Month ensures that only the most recent month of data is refreshed during each cycle, minimizing the amount of data transferred while keeping recent data up to date."
link: "https://learn.microsoft.com/en-us/fabric/data-factory/dataflows-gen2-incremental-refresh"
more: "Learn more about incremental refresh in Dataflow Gen2"
learn: "Dataflow Gen2 Incremental Refresh"
---
You work as a Data Engineer for Mark at MDFT Pro, a well-known training agency. MDFT Pro has deployed a dataflow that processes course enrollment and sales data from various training programs. The dataflow has been experiencing performance issues during refresh operations, as it transfers large amounts of historical data unnecessarily. Mark has asked you to optimize the dataflow to ensure that refresh operations are efficient and only transfer the minimum amount of data needed to keep the analytics current. The sales data needs regular updates to reflect recent transactions, but transferring years of historical data during each refresh is causing unnecessary network load and extended refresh times.

What should you do to resolve this issue while minimizing the amount of data transferred?
