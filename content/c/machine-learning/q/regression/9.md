---
title: "How can you fix this problem?"
type: "question"
layout: "single"
answers:
    - id: answer1
      title: "Increase the 'number of epochs' hyperparameter"
      explain: "Number of epochs specifies how long the model is trained. Increasing the training time will not solve the problem."

    - id: answer2
      title: "Decrease the 'number of epochs' hyperparameter"
      explain: "Number of epochs specifies how long the model is trained. Descreasing the training time will not solve the problem."

    - id: answer3
      title: "Increase the 'step size' hyperparameter"
      correct: true
      
    - id: answer4
      title: "Decrease the 'step size' hyperparameter"
      explain: "Decreasing the step size will not fix the problem. Gradient descent is sometimes getting stuck in false minima on the loss surface because the step size is too small."

more: "Check out my video lesson to learn more about regression."
learn: "Learn about regression"
link: "https://www.mdft.academy/view/courses/automated-machine-learning-with-mlnet/403055-regression/1153071-introducing-linear-regression"
---

You are building a regression model to predict the wind speed at any point on earth during any time of the day. You are training your model with Gradient Descent and you notice that every time you run a training, you get different final loss values. Some models are great, some average, and some very poor. 

How can you fix this problem?